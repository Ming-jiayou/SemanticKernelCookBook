# Semantic Kernel Cookbook

With the rise of LLM, AI has entered the 2.0 era. Compared with previous AI technologies, the threshold has been lowered and the applicability has been enhanced. It is no longer limited to the field of data science, and more different types of jobs and roles of people are participating in large-scale research in the application scenarios of the model. For how traditional engineering projects or enterprise applications to enter the field of LLM, a framework is an important key. Especially for traditional projects, companies must think about how to access LLM faster and at low cost. In 2023, the first year of LLM, the open source community has a lot of frameworks and solutions based on LLM applications. I personally like LangChain, BenToML, and Semantic Kernel. But overall, Semantic Kernel is more suitable for traditional engineering and multi-language engineering teams, LangChain is suitable for data science personnel, and BenToML is suitable for multi-model deployment scenarios. In December 2023, when Semantic Kernel officially releases 1.0.1 based on .NET version, I also hope to use this manual to give you some ways to learn and get started. Although Semantic Kernel still has many imperfections, it does not prevent everyone from learning and using it.

| Session  | Intro | .NET Samples | Python Samples |
|----------|:----------|:-------------:|------:|
| Getting started with LLM | Begin to know LLM, including OpenAI, Azure OpenAI Service and LLM on Hugging face | Click | Click |
| Semantic Kernel's Basic concept | What is Semantic Kernel? What are its advantages and disadvantages? Semantic Kernel related concepts, etc. | Click | Click |
| The skills of LLM - Plugins | We know that communicating with LLM requires the use of prompt engineering? For enterprise applications, <br/>there are many business-oriented prompt engineering. In Semantic Kernel we call it Plugins. In this session we will introduce how to use Semantic Kernel Plugins and how to define your own Plugins | Click | Click |
| Planner - Let LLM have planning work | Human beings need to complete a job step by step, and the same goes for LLMs. Semantic Kernel has a very powerful task planning capability - Planner<br/>, in this session we will explain in detail how to define and use Planner to make your application more intelligent | Click | Click |
| Embedding Skills  | Building RAG applications is the most commonly used LLM solution at this stage. It is very convenient to build RAG applications through Semantic Kernel<br/>. This session will tell you how to use Semantic Kernel Embeddings  | Click | Click |
| HandsOnLab | Through three hands on labs projects, let everyone truly understand the application of Semantic Kernel | Click | Click |

